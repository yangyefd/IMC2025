import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
import joblib

# 1. 创建 StandardScaler 并手动设置参数
scaler = StandardScaler(with_mean=True, with_std=True)
scaler.mean_ = np.array([422.43776824034336, 0.30263118922746785, 0.16216090258798282, 0.12023845988841203, 0.8682175001287553, 0.25996893914163094, 0.17923020503433476, 0.37973751085836904, 5.567181291845493, 541.2482884978541, 421.82692927038624, 530.8147955107296, 357.6480710472103, 154.36237608154508, 137.9271212060086, 149.63573927897, 139.10412641630901, 171.59602671520943, 161.3243954004292, 35.04014949770816, 36.547855879613735, 385693.39267381973, 377730.49, 0.0017204245194549356, 0.0017298633384420603, 1.2249326760944204, 1.0866756260085837, 0.3618219391802575, 0.7214015079085309, 0.0896342126506438, 0.17241657660085838, 1.417177709527897, 2.3754868085450647, 8.034334763948499, 425.18622944771016, 238.03405547253058, 0.30230578549356224, 0.06540604024892703, 7.939914163090129, 419.68930703297667, 226.09930687905728, 0.3029565964806866, 0.0686220412446352, 0.9838696686073622, 1.0161303313926378, 1.0004499757081544, 0.9995500057510729])  # 从 OCR 获取的均值
scaler.scale_ = np.array([430.8876223830481, 0.10120305458413023, 0.042338948512145654, 0.06619656152915714, 0.1537269812875491, 0.10397368883078202, 0.08278769906036262, 0.13282659069659564, 1.4674949727753823, 296.9289589135243, 174.49266801382944, 298.17680746647517, 157.35755894872017, 94.6877647974455, 53.838266355541634, 90.11423942262311, 52.25750612830233, 186.7008297231772, 153.9923987271926, 35.81372956176768, 34.80907514368333, 296357.56964938506, 286261.54315867735, 0.0020023863531397844, 0.0019942797420357096, 1.0117178443793309, 0.3669343406655899, 0.509153085447823, 0.2237743145160967, 0.04982373274128422, 0.023596993005985046, 0.6626036311814616, 3.218431654900108, 2.7072667447056067, 347.39870883686484, 117.48356069966182, 0.07016784212033654, 0.035738448606466834, 2.5984138429183665, 338.1657650717025, 121.192967738248, 0.06721636481496976, 0.02789567300376701, 0.8507031259510917, 0.9009443196895954, 0.2197639954350916, 0.2398865664024024])  # 从 OCR 获取的标准差

scaler.var_ = scaler.scale_ ** 2  # var_ 是 scale_ 的平方，scikit-learn 需要

# 2. 创建 LogisticRegression 并设置参数
logreg = LogisticRegression(
    penalty='l2',
    C=1.0,
    solver='liblinear',
    max_iter=10000,
    class_weight='none',
    random_state=42,
    fit_intercept=True
)

# 手动设置训练后的参数
logreg.coef_ = np.array([[0.39236208725383853, -0.08798133971102229, 0.29451183130057185, -0.005594120909124197, -0.3986118107422639, -0.45298820793883615, 0.158789379232862, -0.29573716842297454, 0.747855579423738, -0.2364337706597849, -0.5263045965646268, 0.3649976249585288, 1.0544430213291442, 0.03778395522172543, 0.8187946448234699, -0.2572788862437131, -0.2208200214205765, -0.40589664002446535, 0.25047254032700406, 0.49196634183931653, 0.15015421146713862, 0.21508721515458323, -0.25377867666234244, 0.04598751063420907, 0.32730312281990365, 0.49973918082815155, 0.1310109595531551, 0.3599712485779956, 0.8209642293758023, -0.1881098823217313, 0.1790507492330868, 0.3529523991627226, -0.07244122000472664, -0.13442119384379092, 1.1763309782828035, -0.6199279463355979, -0.18604117289063055, 1.0881393562361168, -0.4366857915660599, 0.6765606277628254, -0.24092463767850134, -0.7432003806176521, 0.028933782037047162, 0.26520330454559465, 0.2021686746407571, 0.540012419448719, 0.46714693049760553]])  # 形状为 [n_classes, n_features]
logreg.intercept_ = np.array([2.40118352])  # 形状为 [n_classes]
logreg.classes_ = np.array([0, 1])  # 假设二分类，类标签为 0 和 1
logreg.n_features_in_ = 47  # 特征数量

feature_names = ['num_matches', 'score_mean', 'score_std', 'score_min', 'score_max', 'score_median', 'score_q25', 'score_q75', 'score_top_bottom_ratio', 'kp1_x_mean', 'kp1_y_mean', 'kp2_x_mean', 'kp2_y_mean', 'kp1_x_std', 'kp1_y_std', 'kp2_x_std', 'kp2_y_std', 'kp_x_mean_diff', 'kp_y_mean_diff', 'kp_x_std_diff', 'kp_y_std_diff', 'kp1_area', 'kp2_area', 'kp1_density', 'kp2_density', 'area_ratio', 'distance_ratio_mean', 'distance_ratio_std', 'distance_ratio_consistency', 'desc_sim_mean', 'desc_sim_std', 'score_skew', 'score_kurtosis', 'key1_connections', 'key1_matches_mean', 'key1_matches_std', 'key1_scores_mean', 'key1_scores_std', 'key2_connections', 'key2_matches_mean', 'key2_matches_std', 'key2_scores_mean', 'key2_scores_std', 'key1_matches_ratio', 'key2_matches_ratio', 'key1_scores_ratio', 'key2_scores_ratio']

# 4. 保存为 pkl 文件
joblib.dump(scaler, './lr_model/scaler.pkl')
joblib.dump(logreg, './lr_model/lr_model.pkl')
joblib.dump(feature_names, './lr_model/feature_names.pkl')

#检查sum
print("scaler.mean_:", scaler.mean_.sum(),scaler.mean_.shape)
print("scaler.scale_:", scaler.scale_.sum(),scaler.scale_.shape)
print("logreg.coef_:", logreg.coef_.sum(),logreg.coef_.shape)
