import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
import joblib

# 1. 创建 StandardScaler 并手动设置参数
scaler = StandardScaler(with_mean=True, with_std=True)
scaler.mean_ = np.array([889.424149362069, 0.6466299371104789, 2.80768205771996, 0.6116706812550345, 
  0.434804929548132, 0.2830919282575732, 0.6695798375298755, 5.841579961167143, 
  527.6820743299634, 99.7398224311462, 1.471690322774869, 0.14936683974447137, 
  0.4881481284022878, 0.0894076112487895, 127.84899829820434, 99.7398224311462, 
  1.471690322774869, 0.14936683974447137, 0.4881481284022878, 0.0894076112487895, 
  127.84899829820434, 99.7398224311462, 1.471690322774869, 0.14936683974447137, 
  0.4881481284022878, 0.0894076112487895, 127.84899829820434, 99.7398224311462, 
  1.471690322774869, 0.14936683974447137, 0.4881481284022878, 0.0894076112487895, 
  127.84899829820434, 99.7398224311462, 1.471690322774869, 0.14936683974447137, 
  0.4881481284022878, 0.0894076112487895, 127.84899829820434, 99.7398224311462, 
  1.471690322774869, 0.14936683974447137, 0.4881481284022878, 0.0894076112487895, 
  127.84899829820434, 99.7398224311462, 1.471690322774869])  # 从 OCR 获取的均值
scaler.scale_ = np.array([536.1857122094093, 0.4282615912866643, 1.2007733136045413, 0.353612051864094, 
  0.5316503420857413, 0.1941740943623625, 0.6960509994879406, 1.1241674973675943, 
  0.12417697269736543, 1.0036662075991202, 1.3786779452848222, 0.7070635635298761, 
  0.4970740891564706, 0.22988822049192144, 2.2256892097482386, 0.12417697269736543, 
  1.0036662075991202, 1.3786779452848222, 0.7070635635298761, 0.4970740891564706, 
  0.22988822049192144, 2.2256892097482386, 0.12417697269736543, 1.0036662075991202, 
  1.3786779452848222, 0.7070635635298761, 0.4970740891564706, 0.22988822049192144, 
  2.2256892097482386, 0.12417697269736543, 1.0036662075991202, 1.3786779452848222, 
  0.7070635635298761, 0.4970740891564706, 0.22988822049192144, 2.2256892097482386, 
  0.12417697269736543, 1.0036662075991202, 1.3786779452848222, 0.7070635635298761, 
  0.4970740891564706, 0.22988822049192144, 2.2256892097482386, 0.12417697269736543, 
  1.0036662075991202, 1.3786779452848222, 0.7070635635298761])  # 从 OCR 获取的标准差

scaler.var_ = scaler.scale_ ** 2  # var_ 是 scale_ 的平方，scikit-learn 需要

# 2. 创建 LogisticRegression 并设置参数
logreg = LogisticRegression(
    penalty='l2',
    C=1.0,
    solver='liblinear',
    max_iter=10000,
    class_weight='none',
    random_state=42,
    fit_intercept=True
)

# 手动设置训练后的参数
logreg.coef_ = np.array([[0.2977506159602513, 0.01480583528052672, 0.5727442018162526, 
  -0.1865666628726537, -0.3715290875865737, -0.08340839652159176, 
  0.065731646144379, 0.0, -0.5218385670215193, 0.0, -0.01275219405640591, 
  -0.1769061431760291, 0.4780595510735774, 0.17989471782589, 0.2423414886418121, 
  -0.2518927515264944, -0.1928572971234774, 0.0, -0.698384227816548, 
  0.2761933212311, -0.0935095289411439, -0.0527738553534143, -0.082202716073, 
  -0.08308351543013864, 0.4741092634423676, 0.6481417202540024, 0.3641042856636926, 
  -0.2222131935432099, 0.4787297320123111, -0.3808272667463741, -0.48144662876, 
  0.2358167822156, 0.5637473531286, 0.6227543064999655, 0.7957080366086806, 
  0.445826785219486, 0.586096752613871, -0.26387997386663]])  # 形状为 [n_classes, n_features]
logreg.intercept_ = np.array([3.48449395])  # 形状为 [n_classes]
logreg.classes_ = np.array([0, 1])  # 假设二分类，类标签为 0 和 1
logreg.n_features_in_ = 47  # 特征数量

feature_names = ['num_matches', 'score_mean', 'score_std', 'score_min', 'score_max', 'score_median', 'score_q25', 'score_q75', 'score_top_bottom_ratio', 'kp1_x_mean', 'kp1_y_mean', 'kp2_x_mean', 'kp2_y_mean', 'kp1_x_std', 'kp1_y_std', 'kp2_x_std', 'kp2_y_std', 'kp_x_mean_diff', 'kp_y_mean_diff', 'kp_x_std_diff', 'kp_y_std_diff', 'kp1_area', 'kp2_area', 'kp1_density', 'kp2_density', 'area_ratio', 'distance_ratio_mean', 'distance_ratio_std', 'distance_ratio_consistency', 'desc_sim_mean', 'desc_sim_std', 'score_skew', 'score_kurtosis', 'key1_connections', 'key1_matches_mean', 'key1_matches_std', 'key1_scores_mean', 'key1_scores_std', 'key2_connections', 'key2_matches_mean', 'key2_matches_std', 'key2_scores_mean', 'key2_scores_std', 'key1_matches_ratio', 'key2_matches_ratio', 'key1_scores_ratio', 'key2_scores_ratio']

# 4. 保存为 pkl 文件
joblib.dump(scaler, './lr_model/scaler.pkl')
joblib.dump(logreg, './lr_model/lr_model.pkl')
joblib.dump(feature_names, './lr_model/feature_names.pkl')

#检查sum
print("scaler.mean_:", scaler.mean_.sum(),scaler.mean_.shape)
print("scaler.scale_:", scaler.scale_.sum(),scaler.scale_.shape)
print("logreg.coef_:", logreg.coef_.sum(),logreg.coef_.shape)
